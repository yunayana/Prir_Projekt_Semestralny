# ğŸ•· Web Crawler Distributed Application

Projekt aplikacji rozproszonej do selektywnego pobierania danych z witryn internetowych wedÅ‚ug zadanych profili. Zrealizowano z wykorzystaniem technologii: Python, Flask, MongoDB, multiprocessing, asyncio oraz Docker.

## ğŸ“Œ Opis projektu

Aplikacja pobiera, przetwarza i zapisuje dane zgodne z ustalonym profilem danych. CaÅ‚oÅ›Ä‡ zostaÅ‚a podzielona na 3 moduÅ‚y:

- **Interfejs uÅ¼ytkownika (Flask)**
- **Silnik przetwarzajÄ…cy (multiprocessing + asyncio)**
- **Baza danych (MongoDB)**

## ğŸ“ Struktura danych

Pobrane dane dzielÄ… siÄ™ na 4 gÅ‚Ã³wne grupy:
1. Adresy e-mail
2. Adresy korespondencyjne
3. Schematy organizacyjne (struktura firm, nazwiska)
4. Linki zewnÄ™trzne i zasoby (np. do dokumentÃ³w PDF, DOCX)

## âš™ï¸ Technologie

- Python 3.10
- Flask
- BeautifulSoup4
- asyncio + multiprocessing
- MongoDB (zdalna lub lokalna w Dockerze)
- Docker + Docker Compose

## ğŸ§  Architektura


- tmge_prir/
  - gui/
    - app.py
    - templates/
    - static/
      - img/
        - Band_Maid.jpg
        - Buck_Tick.jpg
      - style.css
    - requirements.txt
    - Dockerfile
  - scraper/
    - scraper.py
    - mongo_test.py
    - requirements.txt
    - Dockerfile
  - docker-compose.yml
  - README.md





### ğŸ“¦ ModuÅ‚y Dockera

- `frontend`: Serwer Flask (interfejs uÅ¼ytkownika)
- `crawler`: GÅ‚Ã³wny silnik przetwarzajÄ…cy dane
- `mongodb`: Baza danych z danymi wejÅ›ciowymi i wynikami

## ğŸš€ Uruchomienie

```bash
git clone https://github.com/yunayana/tmge_prir.git
cd tmge_prir
docker-compose up --build

