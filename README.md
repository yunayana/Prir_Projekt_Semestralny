#  Web Crawler Distributed Application

Projekt aplikacji rozproszonej do selektywnego pobierania danych z witryn internetowych wedug zadanych profili. Zrealizowano z wykorzystaniem technologii: Python, Flask, MongoDB, multiprocessing, asyncio oraz Docker.

##  Opis projektu

Aplikacja pobiera, przetwarza i zapisuje dane zgodne z ustalonym profilem danych. Cao zostaa podzielona na 3 moduy:

- **Interfejs u偶ytkownika (Flask)**
- **Silnik przetwarzajcy (multiprocessing + asyncio)**
- **Baza danych (MongoDB)**

##  Struktura danych

Pobrane dane dziel si na 4 g贸wne grupy:
1. Adresy e-mail
2. Adresy korespondencyjne
3. Schematy organizacyjne (struktura firm, nazwiska)
4. Linki zewntrzne i zasoby (np. do dokument贸w PDF, DOCX)

## 锔 Technologie

- Python 3.10
- Flask
- BeautifulSoup4
- asyncio + multiprocessing
- MongoDB (zdalna lub lokalna w Dockerze)
- Docker + Docker Compose

##  Architektura


- tmge_prir/
  - gui/
    - app.py
    - templates/
    - static/
      - img/
        - Band_Maid.jpg
        - Buck_Tick.jpg
      - style.css
    - requirements.txt
    - Dockerfile
  - scraper/
    - scraper.py
    - mongo_test.py
    - requirements.txt
    - Dockerfile
  - docker-compose.yml
  - README.md





###  Moduy Dockera

- `frontend`: Serwer Flask (interfejs u偶ytkownika)
- `crawler`: G贸wny silnik przetwarzajcy dane
- `mongodb`: Baza danych z danymi wejciowymi i wynikami

##  Uruchomienie

```bash
git clone https://github.com/yunayana/tmge_prir.git
cd tmge_prir
docker-compose up --build
http://localhost:5003
```
##  Zrzuty ekranu

### Terminal 
![Terminal output](images/building.png)

### Docker - obrazy kontener贸w
![Docker images](images/docker.png)

### Baza - zrzut z MongoDB
![Data_Mongo](images/base.png)


